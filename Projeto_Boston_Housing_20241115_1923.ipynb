{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1n_4Fi6g6qk"
      },
      "source": [
        "# **Projeto Boston Housing**\n",
        "\n",
        "Neste projeto você deverá desenvolver um projeto offline de ponta a ponta. Nesta atividade, porém, vamos trabalhar com o Boston Housing.\n",
        "Você pode fazer em dupla, mas todos os membros devem participar de todas as etapas, inclusive da gravação do vídeo (ver etapa 3). Todos os membros da equipe devem fazer submissão individual no moodle, ainda que o trabalho seja feito em equipe.\n",
        "\n",
        "As etapas do projeto são as seguintes:\n",
        "\n",
        "Desenvolver o projeto completamente, o que consiste:\n",
        "\n",
        "1. Descrição do conjunto de dados;\n",
        "\n",
        "2. Separação do conjunto em treino e teste;\n",
        "\n",
        "3. Visualização do conjunto de dados (análise exploratória básica);\n",
        "\n",
        "4. Preparação do conjunto de dados;\n",
        "\n",
        "5. Comparar ao menos 3 modelos de machine learning e algumas configuração de hiperparâmetros, justificando a escolha do melhor modelo;\n",
        "\n",
        "6. Você deve ainda justificar a escolha da métrica utilizada;\n",
        "\n",
        "7. Deve discutir a técnica utilizada para validar o modelo e deve explicar como que o seu modelo evita o \"snooping bias/data leakage\";\n",
        "\n",
        "8. Fazer teste final para obter um erro aproximado.\n",
        "\n",
        "2 - A segunda etapa consiste em você disponibilizar o projeto no GitHub, através de um link. Você não precisa se aprofundar em GitHub, é suficiente você criar uma conta e fazer upload manualmente pelo browser.  A ideia é que você se acostume a criar um portfólio para as suas atividades sorriso\n",
        "\n",
        "3 - A terceira etapa consite em você gravar um vídeo de, no máximo, 15 min (20 min se feito em dupla). Neste vídeo você fará uma apresentação dos principais pontos do projeto, ilustrando quais foram as dificuldades. Precisa ficar claro que você domina todas as etapas de um projeto de ML offline. Minha sugestão é fazer upload em um link privado do YouTube, se ficar bom você pode deixar público para o portfólio de vocês.\n",
        "\n",
        "4 - O formato da entrega é jupyter notebook para o projeto, lá você pode adicionar o link para o vídeo também.\n",
        "\n",
        "Você pode encontrar as informações e o dataset aqui nesse link.\n",
        "\n",
        "Dica: Revise aulas sobre Califórnia Housing, assim como o notebook disponível no meu github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mN5MCeIjihO"
      },
      "source": [
        "# 0. Importa Dados Boston Housing\n",
        "\n",
        "Fonte: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
        "\n",
        "Existem 14 atributos em cada caso do conjunto de dados. Eles são:\n",
        "\n",
        "CRIM - taxa de criminalidade per capita por cidade\n",
        "\n",
        "ZN - proporção de terrenos residenciais zoneados para lotes acima de 25.000 pés quadrados\n",
        "\n",
        "INDUS - proporção de acres de negócios não varejistas por cidade.\n",
        "\n",
        "CHAS - Variável fictícia do Rio Charles (1 se o trato limita o rio; 0 caso contrário)\n",
        "\n",
        "NOX - concentração de óxidos nítricos (partes por 10 milhões)\n",
        "\n",
        "RM - número médio de cômodos por moradia\n",
        "\n",
        "AGE - proporção de unidades ocupadas pelo proprietário construídas antes de 1940\n",
        "\n",
        "DIS - distâncias ponderadas para cinco centros de emprego de Boston\n",
        "\n",
        "RAD - índice de acessibilidade a rodovias radiais\n",
        "\n",
        "TAX - taxa de imposto sobre a propriedade com valor integral por US$ 10.000\n",
        "PTRATIO - proporção aluno-professor por cidade\n",
        "\n",
        "B - 1000(Bk - 0,63)^2 onde Bk é a proporção de negros por cidade\n",
        "\n",
        "LSTAT - % de status inferior da população\n",
        "\n",
        "MEDV - Valor mediano de casas ocupadas pelo proprietário em US$ 1.000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CsnXWe5plrJq"
      },
      "outputs": [],
      "source": [
        "#### INSTALAR isso =)\n",
        "!pip install dash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ujp5xMKUztyp"
      },
      "outputs": [],
      "source": [
        "#### Replicabilidade das Coisas\n",
        "seed = 26011994"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W1t2LoEjls6o"
      },
      "outputs": [],
      "source": [
        "#### Libs\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G33ePXusjqeG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# URL do dataset no UCI Machine Learning Repository\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
        "\n",
        "# Definindo os nomes das colunas (segundo a documentação do dataset no UCI)\n",
        "column_names = [\n",
        "    \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\",\n",
        "    \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"\n",
        "]\n",
        "\n",
        "# Carregando o dataset\n",
        "housing = pd.read_csv(url, delim_whitespace=True, names=column_names)\n",
        "\n",
        "# Exibindo as primeiras linhas\n",
        "print(housing.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSyWuXSAqu4g"
      },
      "source": [
        "### ** Note que existem variáveis inteiras as quais não necessáriamente representam quantidades. **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4udK-xirrb"
      },
      "source": [
        "# 1. Descrição do conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SGDq7YdQxp-4"
      },
      "outputs": [],
      "source": [
        "housing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7icSq8-4gpdS"
      },
      "outputs": [],
      "source": [
        "round(housing.describe(),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N-a7xj8Wx_q_"
      },
      "outputs": [],
      "source": [
        "### Verifica Missing\n",
        "\n",
        "# Calcular o percentual de valores ausentes por variável\n",
        "missing_percentage = housing.isnull().mean() * 100\n",
        "\n",
        "# Criar um DataFrame para exibir de forma mais clara\n",
        "missing_df = missing_percentage.reset_index()\n",
        "missing_df.columns = ['Variável', 'Percentual de Missing']\n",
        "missing_df = missing_df.sort_values(by='Percentual de Missing', ascending=False)\n",
        "\n",
        "# Exibir o resultado\n",
        "print(missing_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6BJsM8GEyl4S"
      },
      "outputs": [],
      "source": [
        "# @title CHAS - Variável fictícia do Rio Charles (1 se o trato limita o rio; 0 caso contrário)\n",
        "housing.loc[:,['CHAS']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "mHUCzVrWlFV0"
      },
      "outputs": [],
      "source": [
        "# @title Dashboard de Análise Descritiva\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "df = housing\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Dashboard de Análise Descritiva\"),\n",
        "\n",
        "    # Dropdown para selecionar a variável\n",
        "    html.Label(\"Selecione a variável:\"),\n",
        "    dcc.Dropdown(\n",
        "        id='dropdown-variable',\n",
        "        options=[{'label': col, 'value': col} for col in df.columns],\n",
        "        value='MEDV'\n",
        "    ),\n",
        "\n",
        "    # Saída das estatísticas descritivas\n",
        "    html.Div(id='output-descriptive-stats'),\n",
        "\n",
        "    # Gráfico de distribuição\n",
        "    dcc.Graph(id='output-distribution-plot')\n",
        "])\n",
        "\n",
        "# Callback para atualizar as estatísticas descritivas e o gráfico de distribuição\n",
        "@app.callback(\n",
        "    [Output('output-descriptive-stats', 'children'),\n",
        "     Output('output-distribution-plot', 'figure')],\n",
        "    [Input('dropdown-variable', 'value')]\n",
        ")\n",
        "def update_output(variable):\n",
        "    # Estatísticas descritivas\n",
        "    desc_stats = df[variable].describe().to_frame().T\n",
        "    desc_table = html.Table([\n",
        "        html.Tr([html.Th(col) for col in desc_stats.columns]),\n",
        "        html.Tr([html.Td(desc_stats[col].values[0]) for col in desc_stats.columns])\n",
        "    ])\n",
        "\n",
        "    # Gráfico de distribuição\n",
        "    fig = px.histogram(df, x=variable, nbins=30, title=f'Distribuição de {variable}')\n",
        "    fig.update_layout(bargap=0.2)\n",
        "\n",
        "    return desc_table, fig\n",
        "\n",
        "# Executa o app\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True , port=8051)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fYhn-641zxY5"
      },
      "outputs": [],
      "source": [
        "# @title Visão De Todas as Variáveis ao Mesmo Tempo\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-1fhJ6kmYKn"
      },
      "source": [
        "Podemos observar, intuitivamente, que nem todas as distribuições seguem uma distibuição normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "jK2MiRdylKYu"
      },
      "outputs": [],
      "source": [
        "# @title Correlação Linear entre Variáveis\n",
        "# Calcular a matriz de correlação\n",
        "correlation_matrix = housing.corr()\n",
        "\n",
        "# Criar o heatmap de correlação com valores sobrepostos\n",
        "fig = px.imshow(correlation_matrix,\n",
        "                text_auto=True,  # Mostra os valores da correlação no gráfico\n",
        "                color_continuous_scale=\"RdBu_r\",\n",
        "                aspect=\"auto\",\n",
        "                title=\"Mapa de Correlação entre Variáveis\")\n",
        "\n",
        "# Exibir o gráfico\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeGxSG10s6Md"
      },
      "source": [
        "Aqui vale ressaltar que o a variável CHAS é uma representação numérica aleatória de categorias sem relação de ordem. Assim, a análise de correção perde um pouco do sentido.\n",
        "\n",
        "Será interessante olhar outras méticas mais fortes que nos diga se de fato ela será poderosa em nosso modelo, ou não."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "OS5gHfEpn_9c"
      },
      "outputs": [],
      "source": [
        "# @title ### **Vamos analisar se existe algum padrão aparente entre as variáveis coletadas e a variável alvo (MEDV)**\n",
        "import pandas as pd\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "\n",
        "df = housing\n",
        "# Inicialização do app Dash\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Dashboard de Correlação e Regressão com MEDV\"),\n",
        "\n",
        "    # Dropdown para selecionar a variável no eixo X\n",
        "    html.Label(\"Selecione a variável (eixo X):\"),\n",
        "    dcc.Dropdown(\n",
        "        id='dropdown-variable',\n",
        "        options=[{'label': col, 'value': col} for col in df.columns if col != 'MEDV'],\n",
        "        value='LSTAT'\n",
        "    ),\n",
        "\n",
        "    # Gráfico de dispersão\n",
        "    dcc.Graph(id='scatter-plot')\n",
        "])\n",
        "\n",
        "# Callback para atualizar o gráfico de dispersão\n",
        "@app.callback(\n",
        "    Output('scatter-plot', 'figure'),\n",
        "    [Input('dropdown-variable', 'value')]\n",
        ")\n",
        "def update_scatter(variable):\n",
        "    # Calcular o coeficiente de correlação\n",
        "    corr_coef = np.corrcoef(df[variable], df['MEDV'])[0, 1]\n",
        "\n",
        "    # Criar o gráfico de dispersão com linha de regressão\n",
        "    fig = px.scatter(df, x=variable, y=\"MEDV\", trendline=\"ols\",\n",
        "                     title=f'Dispersão de MEDV vs {variable} (Coeficiente de Correlação = {corr_coef:.2f})')\n",
        "\n",
        "    # Adicionar coeficiente de correlação no título\n",
        "    fig.update_layout(title=dict(x=0.5))  # Centraliza o título\n",
        "    fig.update_traces(marker=dict(size=6))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Executa o app\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True, port=8052)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY0zposRsx8l"
      },
      "source": [
        "Aqui observamos mais de perto o comportamento dos dados em relação a variável target.\n",
        "\n",
        "Na análise passada vimos quais tem maior correlação. Como a correlação linear usual é o coeficiente angular da regressão linear entre as duas variáveis, aproveitei para plotar as regresões as  originaram, a fim de observar se estão fazendo sentido.\n",
        "\n",
        "Um **grande perigo** é que podem ocorrer casos em que exista uma var x1 = x2^2. Nesse caso, o coeficente de correlção **linear** será zero, mesmo uma sendo escrita completamente em função da outra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "rtrBsiLduGvm"
      },
      "outputs": [],
      "source": [
        "# @title  Conforme segue o exemplo abaixo.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "# Gerando dados\n",
        "np.random.seed(0)\n",
        "x1 = np.linspace(-10, 10, 100)\n",
        "x2 = x1**2  # x2 é uma função não-linear de x1\n",
        "\n",
        "# Coeficiente de correlação linear\n",
        "correlation, _ = pearsonr(x1, x2)\n",
        "print(f\"Coeficiente de correlação linear entre x1 e x2: {correlation:.2f}\")\n",
        "\n",
        "# Regressão linear\n",
        "slope, intercept, r_value, p_value, std_err = linregress(x1, x2)\n",
        "line = slope * x1 + intercept  # Linha de regressão linear\n",
        "\n",
        "# Plotando\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=x1, y=x2, label=\"Dados\")\n",
        "plt.plot(x1, line, color=\"red\", linestyle=\"--\", label=\"Regressão Linear\")\n",
        "plt.title(f\"Gráfico de x2 = x1^2 com Coeficiente de Correlação Linear = {correlation:.2f}\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8LeTIFo0lvQ"
      },
      "source": [
        "# **2. Separação do conjunto em treino e teste**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iQ6Br4gsIJK8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Função para discretizar variáveis numéricas e estratificar\n",
        "def stratified_sampling(data, max_bins, columns):\n",
        "    df = data.copy()\n",
        "\n",
        "    # Discretizar colunas numéricas\n",
        "    for column in columns:\n",
        "        unique_values = df[column].nunique()\n",
        "        if unique_values > max_bins:\n",
        "            bins = max_bins\n",
        "            df[column + '_decile'] = pd.qcut(df[column], q=bins, labels=[str(i+1) for i in range(bins)], duplicates='drop')\n",
        "        else:\n",
        "            bins = unique_values\n",
        "            df[column + '_decile'] = pd.cut(df[column], bins=bins, labels=[str(i+1) for i in range(bins)], include_lowest=True)\n",
        "\n",
        "    # Criar coluna de estratificação\n",
        "    df['stratify_column'] = df[[col + '_decile' for col in columns]].apply(lambda row: '_'.join(row.astype(str)), axis=1)\n",
        "\n",
        "    # Ajustar classes com menos de 2 observações\n",
        "    class_counts = df['stratify_column'].value_counts()\n",
        "    rare_classes = class_counts[class_counts < 2].index\n",
        "    if len(rare_classes) > 0:\n",
        "        df.loc[df['stratify_column'].isin(rare_classes), 'stratify_column'] = 'OTHER'\n",
        "\n",
        "    # Realizar amostragem estratificada\n",
        "    train, test = train_test_split(df, stratify=df['stratify_column'], test_size=0.25, random_state=42)\n",
        "\n",
        "    # Remover colunas auxiliares\n",
        "    columns_to_drop = [col + '_decile' for col in columns] + ['stratify_column']\n",
        "    train.drop(columns=columns_to_drop, inplace=True)\n",
        "    test.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "# Aplicar amostragem estratificada\n",
        "train_set, test_set = stratified_sampling(\n",
        "    housing,\n",
        "    25,\n",
        "    ['RM', 'DIS', 'LSTAT', 'MEDV']\n",
        ")\n",
        "\n",
        "###Verificar tamanhos\n",
        "print(f\"Train size: {len(train_set)}\")\n",
        "print(f\"Test size: {len(test_set)}\")\n",
        "print(f\"Total: {len(train_set) + len(test_set)}\")\n",
        "print('Train: '+ str(round(train_set.shape[0]/housing.shape[0], 4)*100) +'%')\n",
        "print('Test: ' + str(round(test_set.shape[0] /housing.shape[0], 4)*100) +'%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_rrnCpvOCIp"
      },
      "source": [
        "Vamos criar uma amostragem aleátoria para fins de comparação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bzAHoScaJAn5"
      },
      "outputs": [],
      "source": [
        "train_set_aleatorio, test_set_aleatorio = train_test_split(housing, test_size=0.2, random_state=seed)\n",
        "print('Train: '+ str(round(train_set_aleatorio.shape[0]/housing.shape[0], 4)*100) +'%')\n",
        "print('Test: ' + str(round(test_set_aleatorio.shape[0] /housing.shape[0], 4)*100) +'%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "at3Ju1Xo8gx1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_train_test_distributions_percentual(housing, train, test,  columns):\n",
        "    plt.figure(figsize=(24, 18))  # Ajuste do tamanho para comportar mais informações\n",
        "    for i, column in enumerate(columns, 1):\n",
        "        plt.subplot(5, 4, i)  # Ajusta a grade para 5x4, caso tenha mais colunas\n",
        "        housing[column].hist(bins=50, alpha=0.5, label='Housing', color='purple', density=True, linewidth=0.7, edgecolor='black')\n",
        "        train[column].hist(bins=50, alpha=0.5, label='Train Stratified', color='blue', density=True, linewidth=0.7, edgecolor='black')\n",
        "        test[column].hist(bins=50, alpha=0.5, label='Test Stratified', color='orange', density=True, linewidth=0.7, edgecolor='black')\n",
        "\n",
        "        plt.title(column, fontsize=12)\n",
        "        plt.xlabel('Value', fontsize=10)\n",
        "        plt.ylabel('Density', fontsize=10)\n",
        "        plt.legend(loc='upper right', fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Aplicar a função para visualizar distribuições percentuais\n",
        "plot_train_test_distributions_percentual(\n",
        "    housing, train_set, test_set, train_set.columns\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FVGv3q5oPIYh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_variable_bins_with_labels(housing, columns, bins=10):\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    for i, column in enumerate(columns, 1):\n",
        "        plt.subplot(4, 4, i)\n",
        "\n",
        "        # Criar bins com descrição dos intervalos\n",
        "        housing_bins = pd.cut(housing[column], bins=bins, include_lowest=True)\n",
        "        bin_counts = housing_bins.value_counts(normalize=True).sort_index()\n",
        "\n",
        "        # Extrair labels descritivos dos intervalos\n",
        "        bin_labels = [f\"{interval.left:.2f} - {interval.right:.2f}\" for interval in bin_counts.index]\n",
        "\n",
        "        # Plotar distribuição percentual\n",
        "        plt.bar(bin_labels, bin_counts.values, color='blue', alpha=0.7)\n",
        "        plt.title(f'{column} - Distribution')\n",
        "        plt.xlabel('Intervals')\n",
        "        plt.ylabel('Percentage')\n",
        "        plt.xticks(rotation=45, ha='right')  # Rotacionar rótulos para melhor visualização\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plotar distribuições de todas as variáveis do conjunto housing\n",
        "plot_variable_bins_with_labels(housing, housing.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "fVMkdfStiyBF"
      },
      "outputs": [],
      "source": [
        "# @title Verifica Eficiência da Amostragem Estratificada\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def variable_bins_dist(df_referencia_tmp, df_tmp, columns, bins=20):\n",
        "    \"\"\"\n",
        "    Aplica bins consistentes baseados no dataframe de referência a outro dataframe\n",
        "    e retorna a distribuição normalizada das variáveis binned.\n",
        "\n",
        "    Args:\n",
        "    - df_referencia: DataFrame de referência para calcular os bins.\n",
        "    - df: DataFrame ao qual os bins serão aplicados.\n",
        "    - columns: Lista de colunas para aplicar o binning.\n",
        "    - bins: Número de bins a criar.\n",
        "\n",
        "    Returns:\n",
        "    - bin_counts: DataFrame com as distribuições normalizadas das variáveis.\n",
        "    \"\"\"\n",
        "    df_referencia = df_referencia_tmp.copy()\n",
        "    df = df_tmp.copy()\n",
        "\n",
        "    bin_counts = pd.DataFrame()\n",
        "\n",
        "    # Criar bins com base no df_referencia\n",
        "    bin_edges = {}\n",
        "    for column in columns:\n",
        "        # Verificar se a coluna contém valores numéricos\n",
        "        if not pd.api.types.is_numeric_dtype(df_referencia[column]):\n",
        "            raise ValueError(f\"A coluna {column} não é numérica. Verifique os dados.\")\n",
        "\n",
        "        # Remover NaNs antes de calcular os limites\n",
        "        col_data = df_referencia[column].dropna()\n",
        "\n",
        "        # Obter os limites dos intervalos dos bins\n",
        "        _, bin_edges[column] = pd.cut(col_data, bins=bins, retbins=True, include_lowest=True)\n",
        "\n",
        "    # Aplicar os bins ao df e calcular a distribuição\n",
        "    for column in columns:\n",
        "        # Substituir NaNs por um valor para evitar erros\n",
        "        df[column] = df[column].fillna(df[column].median())\n",
        "\n",
        "        # Aplicar os bins usando os limites calculados\n",
        "        df['binned_' + column] = pd.cut(df[column], bins=bin_edges[column], include_lowest=True)\n",
        "        counts = df['binned_' + column].value_counts(normalize=True).sort_index().reset_index()\n",
        "\n",
        "        # Adicionar os nomes corretos às colunas\n",
        "        counts.columns = ['Ranks', 'Perc_Distribuicao']\n",
        "        counts['Variavel'] = column\n",
        "\n",
        "        # Reorganizar as colunas para manter a ordem\n",
        "        counts = counts[['Variavel', 'Ranks', 'Perc_Distribuicao']]\n",
        "\n",
        "        # Concatenar com o DataFrame de resultados\n",
        "        bin_counts = pd.concat([bin_counts, counts], ignore_index=True)\n",
        "\n",
        "    return bin_counts\n",
        "\n",
        "# Exemplo de uso:\n",
        "# Certifique-se de que `columns` contém apenas colunas numéricas.\n",
        "columns = housing.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Calcular distribuições no dataset de referência\n",
        "dist_housing = variable_bins_dist(housing, housing, columns, bins=10)\n",
        "\n",
        "# Aplicar os mesmos bins no test_set e no test_set_aleatorio\n",
        "dist_test_set = variable_bins_dist(housing, test_set, columns, bins=10)\n",
        "dist_test_set_aleatorio = variable_bins_dist(housing, test_set_aleatorio, columns, bins=10)\n",
        "\n",
        "# Adicionar uma coluna de origem para identificar os DataFrames\n",
        "dist_housing['Origem'] = 'housing'\n",
        "dist_test_set['Origem'] = 'test_set'\n",
        "dist_test_set_aleatorio['Origem'] = 'test_set_aleatorio'\n",
        "\n",
        "# Concatenar os DataFrames verticalmente\n",
        "final_df = pd.concat([dist_housing, dist_test_set, dist_test_set_aleatorio], axis=0, ignore_index=True)\n",
        "\n",
        "# Transpor o DataFrame final para organizar as distribuições por variável e rank\n",
        "final_df_pivot = (\n",
        "    final_df.pivot_table(\n",
        "        index=['Variavel', 'Ranks'],  # Índices para o pivot (join será por estes)\n",
        "        columns='Origem',            # Coluna para criar colunas separadas\n",
        "        values='Perc_Distribuicao'   # Valores a serem preenchidos\n",
        "    )\n",
        "    .reset_index()                   # Resetar índice após o pivot\n",
        ")\n",
        "\n",
        "# Renomear colunas para deixar os nomes mais descritivos\n",
        "final_df_pivot.columns = [\n",
        "    'Variavel', 'Ranks',\n",
        "    'Perc_Distribuicao_Housing',\n",
        "    'Perc_Distribuicao_Test_Set',\n",
        "    'Perc_Distribuicao_Test_Set_Aleatorio'\n",
        "]\n",
        "\n",
        "# Preencher valores NaN com 0 (se necessário)\n",
        "final_df_pivot = final_df_pivot.fillna(0)\n",
        "\n",
        "# Calcular a diferença absoluta em relação ao Housing\n",
        "final_df_pivot['Diff_Abs_Test_Set'] = (\n",
        "    abs(final_df_pivot['Perc_Distribuicao_Housing'] - final_df_pivot['Perc_Distribuicao_Test_Set'])\n",
        ")\n",
        "\n",
        "final_df_pivot['Diff_Abs_Test_Set_Aleatorio'] = (\n",
        "    abs(final_df_pivot['Perc_Distribuicao_Housing'] - final_df_pivot['Perc_Distribuicao_Test_Set_Aleatorio'])\n",
        ")\n",
        "\n",
        "final_df_pivot\n",
        "\n",
        "# Agrupar por variável e calcular a média das diferenças absolutas\n",
        "summary_df = (\n",
        "    final_df_pivot.groupby('Variavel')[['Diff_Abs_Test_Set', 'Diff_Abs_Test_Set_Aleatorio']]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Ordenar do maior para o menor com base na diferença absoluta média\n",
        "summary_df = summary_df.sort_values(by=['Diff_Abs_Test_Set', 'Diff_Abs_Test_Set_Aleatorio'], ascending=False)\n",
        "\n",
        "# Renomear colunas para deixá-las mais descritivas\n",
        "summary_df.columns = ['Variavel', 'Media_Diff_Abs_Test_Set', 'Media_Diff_Abs_Test_Set_Aleatorio']\n",
        "summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ea906hL9r8NM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehrByfhxtIL8"
      },
      "source": [
        "#**3. Visualização do conjunto de dados (análise exploratória básica)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mZG2QqdvtOjn"
      },
      "outputs": [],
      "source": [
        "train_set.plot(kind=\"scatter\", x=\"LSTAT\", y=\"RM\",\n",
        "    s=train_set[\"CRIM\"], label=\"Taxa de Criminalidade\", figsize=(10,7),\n",
        "    c=\"MEDV\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        "    sharex=False) #sharex=false é só pra corrigir um bug de display https://github.com/pandas-dev/pandas/issues/10611\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WpEXxUrSt5n9"
      },
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"MEDV\"].sort_values(ascending=False)\n",
        "corr_matrix\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(housing, figsize=(12, 8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSHSSHw0wyYO"
      },
      "source": [
        "#**4. Preparação do conjunto de dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC_s_kDO8jiM"
      },
      "source": [
        "Aqui evitamos o snooping bias estudando o dataframe de train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JISbIYzDwx08"
      },
      "outputs": [],
      "source": [
        "housing = train_set.drop(\"MEDV\", axis=1).copy() # O método drop cria cópia sem a coluna em questao\n",
        "housing_labels = train_set[\"MEDV\"].copy() #salvando uma cópia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JyE_hluExghI"
      },
      "outputs": [],
      "source": [
        "### Verifica Missing\n",
        "\n",
        "# Calcular o percentual de valores ausentes por variável\n",
        "missing_percentage = housing.isnull().mean() * 100\n",
        "\n",
        "# Criar um DataFrame para exibir de forma mais clara\n",
        "missing_df = missing_percentage.reset_index()\n",
        "missing_df.columns = ['Variável', 'Percentual de Missing']\n",
        "missing_df = missing_df.sort_values(by='Percentual de Missing', ascending=False)\n",
        "\n",
        "# Exibir o resultado\n",
        "print(missing_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y7jehCFn0fi2"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer  # Para lidar com valores ausentes\n",
        "from sklearn.preprocessing import StandardScaler  # Para normalizar/padronizar os dados\n",
        "from sklearn.pipeline import Pipeline  # Para criar pipelines\n",
        "from sklearn.preprocessing import FunctionTransformer  # Para transformações personalizadas\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing.select_dtypes(include=[np.number]))\n",
        "housing_num_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jGczLNiy2EKM"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer  # Para transformar colunas específicas\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "num_attribs = list(housing.select_dtypes(include=[np.number]))\n",
        "cat_attribs = list(housing.select_dtypes(include=[object]))\n",
        "\n",
        "#Este é o pipeline completo!\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs), #um pipeline dentro do outro\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "\"\"\" Lembrando: num_pipeline é o pipeline que transforma variavéis numéricas\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "      ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "      ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
        "      ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\"\"\"\n",
        "\n",
        "#### Salva conjunto Preparado\n",
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "housing_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgeae1BtzAyX"
      },
      "source": [
        "#**5. Comparar ao menos 3 modelos de machine learning e algumas configuração de hiperparâmetros, justificando a escolha do melhor modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8U2BoFytx17E"
      },
      "outputs": [],
      "source": [
        "### Regressao Linear\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)\n",
        "#Ei Regressão linear, encontre os parâmetros que melhor aproxima os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FNgk3_-iz1c-"
      },
      "outputs": [],
      "source": [
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data) #Full pipeline\n",
        "\n",
        "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
        "print(\"Labels:\", list(some_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-unMO9Lj3ePa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = MSE(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse) #Não é necessariamente obrigatório\n",
        "print(lin_rmse)\n",
        "print(lin_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iWzoXouz3gsg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "lin_mae = MAE(housing_labels, housing_predictions)\n",
        "lin_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cm00fSCD3vGl"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state= seed, min_weight_fraction_leaf = 0.01) ### Evita overfitting\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ffyrT5nY3wD1"
      },
      "outputs": [],
      "source": [
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = MSE(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US-OuH7b4r-C"
      },
      "source": [
        "##**Avaliação de Modelos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6QBVrMp13yZQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "#cv = 10 é número de pedaços\n",
        "\n",
        "tree_rmse_scores = np.sqrt(-scores)\n",
        "print(tree_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DhuJ4U1C5etH"
      },
      "outputs": [],
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PmwSx_Ct58EE"
      },
      "outputs": [],
      "source": [
        "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ye_9biNN58gU"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42, min_weight_fraction_leaf = 0.01)\n",
        "forest_reg.fit(housing_prepared, housing_labels) #Treinar modelo\n",
        "\n",
        "housing_predictions = forest_reg.predict(housing_prepared) #Predizer\n",
        "forest_mse = MSE(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "print(forest_rmse)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtxsJDrR6kng"
      },
      "source": [
        "#**Ajustando o Modelo Escolhido**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h9ZaGSgK6nem"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    # Vamos tentar 12 = 3x4 combinação de parâmetros\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    # Tentar 6 = 2×3 combinações do bootstrap no modo 'Falso'\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=seed, min_weight_fraction_leaf = 0.01)\n",
        "\n",
        "# Vamos treinar com 5-folds, então temos (12+6)*5=90 rodadas de treinamento!!!\n",
        "\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1ob5RPf6t0N"
      },
      "outputs": [],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k17LVxaO6wtX"
      },
      "outputs": [],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4e3KzlHg6zwn"
      },
      "outputs": [],
      "source": [
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qJGCkLMo7E5n"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(grid_search.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsQAhRw57FeG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=1000),\n",
        "        'max_features': randint(low=1, high=11),\n",
        "    }\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=seed,min_weight_fraction_leaf = 0.01)\n",
        "\n",
        "rnd_search = RandomizedSearchCV(forest_reg,\n",
        "                                param_distributions=param_distribs,\n",
        "                                n_iter=100,\n",
        "                                cv=5,\n",
        "                                scoring='neg_mean_squared_error',\n",
        "                                random_state=seed)\n",
        "\n",
        "rnd_search.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkD17Za58wnW"
      },
      "outputs": [],
      "source": [
        "rnd_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVNeUaBb7K8A"
      },
      "outputs": [],
      "source": [
        "'''cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QgP1yCQ7tQu"
      },
      "outputs": [],
      "source": [
        "feature_importances = grid_search.best_estimator_.feature_importances_\n",
        "feature_importances\n",
        "\n",
        "# Criar um DataFrame com as importâncias e os nomes das variáveis\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': housing.columns,  # Nomes das variáveis\n",
        "    'Importance': feature_importances  # Importância de cada variável\n",
        "})\n",
        "\n",
        "feature_importance_df.sort_values(by='Importance', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3l8ksDi8lZY"
      },
      "source": [
        "#**Modelo e Teste Final**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDlKCDNo8kX3"
      },
      "outputs": [],
      "source": [
        "# 1. Instanciar o modelo\n",
        "final_model_best_params = rnd_search.best_params_\n",
        "final_model = RandomForestRegressor(random_state=seed\n",
        "                                    , min_weight_fraction_leaf = 0.01\n",
        "                                    , **final_model_best_params\n",
        "                                    )\n",
        "\n",
        "# 2. Treinar no conjunto de treino\n",
        "final_model.fit(housing_prepared, housing_labels)\n",
        "\n",
        "# 3. Prever num conjunto\n",
        "X_test = test_set.drop(\"MEDV\", axis=1).copy()\n",
        "y_test = test_set[\"MEDV\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = MSE(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "\n",
        "print(final_rmse)\n",
        "print(final_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46oUhhbj8b20"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurar estilo do seaborn para o gráfico\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Criar um DataFrame para facilitar a manipulação dos dados\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame({\n",
        "    \"Real\": y_test,\n",
        "    \"Predito\": final_predictions\n",
        "})\n",
        "\n",
        "# Configurar o tamanho da figura\n",
        "plt.figure(figsize=(8, 6))  # Tamanho menor\n",
        "\n",
        "# Plotar as distribuições\n",
        "sns.kdeplot(results_df[\"Real\"], label=\"Real\", color=\"blue\", linewidth=1.5, fill=True, alpha=0.3)\n",
        "sns.kdeplot(results_df[\"Predito\"], label=\"Predito\", color=\"orange\", linewidth=1.5, fill=True, alpha=0.3)\n",
        "\n",
        "# Títulos e legendas\n",
        "plt.title(\"Distribuição de MEDV Real vs Predito (Teste)\", fontsize=14)\n",
        "plt.xlabel(\"MEDV\", fontsize=10)\n",
        "plt.ylabel(\"Densidade\", fontsize=10)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(visible=True, alpha=0.3)\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.tight_layout()  # Melhor ajuste\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owVjP-8sBbk5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}